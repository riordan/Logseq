- retrieved:: [[2022/04/07]]
  author:: [[Gabriel Weinberg, Lauren McCann]]
  category:: [[supplementals]]
  source:: [[supplemental]]
  tags:: 
  referrer::readwise
- ![book_image](https://images-na.ssl-images-amazon.com/images/I/51NVQREIpjL._SL200_.jpg){:height 200 :width 200}
- ## [[Readwise Highlights]]
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  Ultimately, to be wrong less, you also need to be testing your assumptions in the real world, a process known as de-risking. There is risk that one or more of your assumptions are untrue, and so the conclusions you reach could also be false.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  When arguing from first principles, you are deliberately starting from scratch. You are explicitly avoiding the potential trap of conventional wisdom, which could turn out to be wrong. Even if you end up in agreement with conventional wisdom, by taking the first-principles approach, you will gain a much deeper understanding of the subject at hand.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  Ockham’s razor helps here. It advises that the simplest explanation is most likely to be true. When you encounter competing explanations that plausibly explain a set of data equally well, you probably want to choose the simplest one to investigate first.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  The concept of inverse thinking can help you with the challenge of making good decisions. The inverse of being right more is being wrong less.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: [[discard]]
	  Unfortunately, people often make the mistake of doing way too much work before testing assumptions in the real world. In computer science this trap is called premature optimization, where you tweak or perfect code or algorithms (optimize) too early (prematurely). If your assumptions turn out to be wrong, you’re going to have to throw out all that work, rendering it ultimately a waste of time.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  Goodhart’s law summarizes the issue: When a measure becomes a target, it ceases to be a good measure.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  Another tactical model that can help you empathize is the most respectful interpretation, or MRI. In any situation, you can explain a person’s behavior in many ways. MRI asks you to you interpret the other parties’ actions in the most respectful way possible. It’s giving people the benefit of the doubt.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  Antifragility is beyond resilience or robustness. The resilient resists shocks and stays the same; the antifragile gets better.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  The central mental model to help you become a chef with your thinking is arguing from first principles. It’s the practical starting point to being wrong less, and it means thinking from the bottom up, using basic building blocks of what you think is true to build sound (and sometimes new) conclusions. First principles are the group of self-evident assumptions that make up the foundation on which your conclusions rest—the ingredients in a recipe or the mathematical axioms that underpin a formula.
	- link:: [null](null)
	  on:: [[2021/01/22]]
	  tags:: 
	  Hanlon’s razor: never attribute to malice that which is adequately explained by carelessness.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  In any conflict between two people, there are two sides of the story. Then there is the third story, the story that a third, impartial observer would recount. Forcing yourself to think as an impartial observer can help you in any conflict situation, including difficult business negotiations and personal disagreements.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  When you try to incentivize behavior by setting a measurable target, people focus primarily on achieving that measure, often in ways you didn’t intend. Most importantly, their focus on the measure may not correlate to the behavior you hoped to promote.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  The human tendency to gather and interpret new information in a biased way to confirm preexisting beliefs is called confirmation bias.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  Sometimes you may want something to be true so badly that you fool yourself into thinking it is likely to be true. This feeling is known as optimistic probability bias, because you are too optimistic about the probability of success.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  As Charlie Munger says, “I never allow myself to have an opinion on anything that I don’t know the other side’s argument better than they do.”
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  Learned helplessness describes the tendency to stop trying to escape difficult situations because we have gotten used to difficult conditions over time. Someone learns that they are helpless to control their circumstances, so they give up trying to change them.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  One technique commonly used in postmortems is called 5 Whys, where you keep asking the question “Why did that happen?” until you reach the root causes.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  A real trick to being wrong less is to fight your instincts to dismiss new information and instead to embrace new ways of thinking and new paradigms.
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  “The best time to plant a tree was twenty years ago. The second best time is now.”
	- link:: [null](null)
	  on:: [[1969/12/31]]
	  tags:: 
	  We call these broadly useful mental models super models because applying them regularly gives you a super power: super thinking—the ability to think better about the world—which you can use to your advantage to make better decisions, both personally and professionally.