title:: articles/How to Measure Data Quality

-
- ## [[Readwise Highlights]]
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  % of days data models are updated within SLA: I like this one because it gives a clear idea of when data is ready to use. If you know your execs look at the KPI dashboard each morning at 9 am, hold yourself and your team accountable for having data ready by then by setting an SLA. There’s no hiding from this.
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags::
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  Weekly active users of a dashboard: Data people should align themselves with the value they create. One of the best ways to do this is by keeping an eye on who uses a data product which in many cases is a dashboard. Not only does this give you visibility into if people use your work but you can also share the success with team members such as analytics engineers or product squads to show them that the upstream work they put into data is paying off.
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  Want to improve data test coverage? Make a rule that every time someone is made aware of a data issue that was not caught by a test, they should add a new test.
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  Segmenting is key
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  Team/squad: If you’re part of a larger data team it’s important to break data quality down by team to understand how each one is doing. Similarly, if you have a decentralised setup with many product squads, you should try getting the data producers to take joint ownership of the data quality by sharing key metrics with them.
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  Criticality: Not all data should be treated the same. An error on a data model that’s only used by you and a few close colleagues may have a very different impact than an error in your top level KPI dashboard or in a data service that powers a production level ML system. Most teams have a way of knowing about this, for example by tagging data models as “tier 1”, “critical” or “gold standard”.
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  Time: You want to be able to understand if you’re improving or deteriorating data quality over time and how this looks across teams and squads.
	- link:: [null](null)
	  on:: [[2022/05/17]]
	  tags:: 
	  End-users: In the same way that you segment data models by criticality, you can segment end-users. For example, you could have a filter on C-suite so you can see which dashboards they use and if they’ve been using wrong data. Although everyone should expect great data quality, it’s often more important to pay extra attention to data that has a lot of senior people using it.